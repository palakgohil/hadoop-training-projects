pystock.sources = source1
pystock.channels = channel1
pystock.sinks = sink1

pystock.sources.source1.type = spoolDir
pystock.sources.source1.channels=channel1
pystock.sources.source1.spoolDir = /home/cloudera/hadoop-class/hadoop-training-projects/flume/large_dir_spool/watch_dir
pystock.sources.source1.includePattern = prices*.\.csv
pystock.sources.source1.ignorePattern= ^((?!prices).)*$

pystock.channels.channel1.type =memory

pystock.sinks.sink1.type=hdfs
pystock.sinks.sink1.channel = channel1
pystock.sinks.sink1.hdfs.path = /user/cloudera/output/handson_train/flume/pystock_data
pystock.sinks.sink1.hdfs.filePrefix = tag_parts_	
pystock.sinks.sink1.hdfs.fileSuffix = .txt
pystock.sinks.sink1.hdfs.rollInterval = 600
pystock.sinks.sink1.hdfs.rollSize = 67108864
pystock.sinks.sink1.hdfs.rollCount = 0
pystock.sinks.sink1.hdfs.writeFormat = Text
pystock.sinks.sink1.hdfs.fileType= DataStream
